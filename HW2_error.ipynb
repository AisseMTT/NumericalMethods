{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Aisse Torres Torres\"\n",
    "COLLABORATORS = \"Bruna Costa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c0e6f80c9a8d85d80baddc8df3890a0",
     "grade": false,
     "grade_id": "cell-7531378247537850",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the factorial function from scipy\n",
    "from scipy.special import factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c047f8ea8a1ba5cc6d067a906fc8242",
     "grade": false,
     "grade_id": "cell-1055125360070174",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# HW 2:  Forms of Error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06a9ac1ce3d93db2a8d123819eb11858",
     "grade": false,
     "grade_id": "cell-9681214437904696",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1:  definition of errors\n",
    "\n",
    "**(a)**  [4 pts] Write a short python program to calculate and return, the absolute error, relative error and degree of decimal precision (as defined in class) given an object $f$ and its approximation $F$.  Note, both f and F can be numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c9bcb87e713e8ee4fb90ec822ed4d9f",
     "grade": false,
     "grade_id": "cell-a6ede65cf8ed685f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def errors(f,F):\n",
    "    \"\"\" calculate various measures of error of an object f and its approximation F\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f:  numpy.array (or float)\n",
    "        array of true values\n",
    "        \n",
    "    F: numpy.array\n",
    "        array of approximate values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    e: array of absolute errors\n",
    "    r: array of relative errors\n",
    "    p: integer array of precisions\n",
    "    \"\"\"\n",
    "    if isinstance(f, (list, numpy.ndarray)):\n",
    "        ab = []\n",
    "        re = []\n",
    "        pr = []\n",
    "        \n",
    "        F_counter = 0; \n",
    "    \n",
    "        for i in numpy.nditer(f):\n",
    "              \n",
    "            absolute = numpy.abs(i - F[F_counter])\n",
    "            relative = absolute / numpy.abs(i) \n",
    "            precision = numpy.intc(-numpy.log10(relative/5.))\n",
    "            \n",
    "            ab.append(absolute)\n",
    "            re.append(relative)\n",
    "            pr.append(precision)\n",
    "            F_counter += 1\n",
    "            \n",
    "        e = numpy.array(ab)\n",
    "        r = numpy.array(re)\n",
    "        p = numpy.array(pr)     \n",
    "    else:\n",
    "        e = numpy.abs(f - F)\n",
    "        r = e / numpy.abs(f)\n",
    "        p = numpy.intc(-numpy.log10(r/5.))\n",
    "        \n",
    "    return e, r, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "756d95f1f1cc55a402f92169c1a8a727",
     "grade": true,
     "grade_id": "cell-da2659b413c73ca7",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "# test simple scalars\n",
    "e,r,p = errors(numpy.exp(1),2.72)\n",
    "numpy.testing.assert_allclose([e,r,p],[0.0017181715409551046, 0.0006320799863232398, 3])\n",
    "\n",
    "# test with array input\n",
    "x = [1., 2., 3.]\n",
    "f = numpy.exp(x)\n",
    "F = [ 2.718,  7.389,  20.085]\n",
    "e,r,p = errors(f,F)\n",
    "numpy.testing.assert_allclose(e,[2.81828459e-04, 5.60989307e-05, 5.36923188e-04])\n",
    "numpy.testing.assert_allclose(r,[1.03678896e-04, 7.59216467e-06, 2.67318315e-05])\n",
    "numpy.testing.assert_allclose(p,[4, 5, 5])\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63298adbbcb0780305df14912e36cad1",
     "grade": false,
     "grade_id": "cell-bef4e3baf992ed93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(b)** [4 pts] Use your routine to calculate various errors for two approximations to $\\pi$\n",
    "\n",
    "* $f = \\pi$ and $F = 3.14$\n",
    "* $f = \\pi$ and $F = 22 / 7$\n",
    "\n",
    "Which of these is the better approximation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0015926535897929917, 0.0005069573828972128, 3)\n",
      "(0.0012644892673496777, 0.0004024994347707008, 4)\n"
     ]
    }
   ],
   "source": [
    "print(errors(numpy.pi, 3.14))\n",
    "print(errors(numpy.pi, 22 / 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9ac9462caae1146fa324fe338dd0c1d",
     "grade": true,
     "grade_id": "cell-4300360216304258",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "    I can see that the relative error and absolute error is smaller when we use 22/7 as the approximation. Furthermore, I can see that 22/7 has a decimal precision of 4, which is higher than the decimal precision of 3.14 (3). Therefore, the better approximation is 22/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56ffae1ca559c1c81f9406aff2676123",
     "grade": false,
     "grade_id": "cell-23707a8e710ca676",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(c)** [4 pts] $F = n log(n) - n$ is Stirling's approximation to  $f = \\log(n!)$ for large values of $n$. \n",
    "Do the following\n",
    "\n",
    "* Make a plot showing the relative error and degree of decimal precision for $f$ and $F$ as a function of integer $n$\n",
    "\n",
    "* Estimate the smallest value of $n$ where Stirling's approximation is good to 4 decimal places of precision.  \n",
    "\n",
    "Note: If you use the `factorial` function imported from `scipy.special`, you will not be able to answer this question.  **Why?**  However there is another way to evaluate $\\log(n!)$ for integer $n$ that will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6195fab472e4537966b7eba4a529a13b",
     "grade": true,
     "grade_id": "cell-a5639245c28a1642",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Decimal Precision')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# helper method for factorial—trying to make a type of memoized solution to reduce runtime for large n \n",
    "def range_prod(lo, hi):\n",
    "    if lo + 1 < hi:\n",
    "        mid = (hi + lo) // 2\n",
    "        return(range_prod(lo, mid) * range_prod(mid + 1, hi))\n",
    "    if lo == hi:\n",
    "        return(lo)\n",
    "    return(lo * hi)\n",
    "\n",
    "# actual function that should be called to compute factorial of a number n \n",
    "def factorial_tree(n):\n",
    "    if n < 2:\n",
    "        return(1)\n",
    "    return(range_product(1, n))\n",
    "\n",
    "def log_fact_tree(n):\n",
    "    # mathematically the same values \n",
    "    return numpy.sum(numpy.log(numpy.arange(1, n + 1)))\n",
    "    \n",
    "def log_stirling(n):\n",
    "    fn = float(n)\n",
    "    fn = fn * math.log(fn) - fn\n",
    "    return(fn)\n",
    "\n",
    "x = [10, 50, 90, 120, 170]\n",
    "y = [0.13761287524946259, 0.019374056732009357, 0.009963045707460885, 0.007237416318162657, 0.004935551797231784]\n",
    "z = [1, 2, 2, 2, 3]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "axs[0].plot(x, y)\n",
    "axs[0].set_xlabel('n')\n",
    "axs[0].set_ylabel('Relative Error')\n",
    "fig.suptitle('Comparing Relative Error and Decimal Precision of log(n!) with Stirlings Approximation', fontsize=16)\n",
    "\n",
    "axs[1].plot(x, z)\n",
    "axs[1].set_xlabel('n')\n",
    "axs[1].set_ylabel('Decimal Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab8966bfa41224e3345e4cd4fcbf9749",
     "grade": true,
     "grade_id": "cell-dcc45d9028355b73",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Stirling's Approximation for log(n!) will be good to 4 decimal places of precision when n is 1452. \n",
    "\n",
    "I got this answer by plugging in values for log_stirling(n) and log_fact_tree(n) and then calculating the absolute, relative error and decimal precision using the console. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd90ff755df8108c8a6c809b037ef098",
     "grade": false,
     "grade_id": "cell-6968179660613369",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "[4 pts] Given the Taylor polynomial expansions\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} = 1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + O(\\Delta x^4)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\cosh \\Delta x = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^6)$$\n",
    "\n",
    "determine the order of approximation for their sum and product (determine the exponent that belongs in the $O$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77d458abae3cfa5157eca11bd346e444",
     "grade": true,
     "grade_id": "cell-8500724062567566",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "    For the sum: \n",
    "\n",
    "$$ \\frac{1}{1-\\Delta x} + \\cosh \\Delta x = 1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + O(\\Delta x^4) + 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^6) $$\n",
    "\n",
    "$$ \\frac{1}{1-\\Delta x} + \\cosh \\Delta x = 2 + \\Delta x + \\Delta x^2(1 + \\frac{1}{2}) + \\Delta x^3  +  O(\\Delta x^4) + O(\\Delta x^6) $$\n",
    "\n",
    "    Note that: \n",
    "    \n",
    "$$ O(\\Delta x^4) + \\frac{\\Delta x^4}{4!} = O(\\Delta x^4) $$\n",
    "\n",
    "    and\n",
    "\n",
    "$$ O(\\Delta x^4) + O(\\Delta x^6) = O(\\Delta x^4) $$\n",
    "\n",
    "$$ \\therefore \\frac{1}{1-\\Delta x} + \\cosh \\Delta x = 2 + \\Delta x + \\frac{3 \\Delta x^2}{2!} + \\Delta x^3 + O(\\Delta x^4) $$\n",
    "\n",
    "    Order of Approximation: \n",
    "    \n",
    "$$ O(\\Delta x^4) $$\n",
    "\n",
    "    For the product: \n",
    "\n",
    "$$ (\\frac{1}{1-\\Delta x})(\\cosh \\Delta x) = (1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + O(\\Delta x^4))(1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^6))$$\n",
    "\n",
    "$$ = (1 + \\Delta x + \\Delta x^2 + \\Delta x^3)(1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!}) + (1 + \\Delta x + \\Delta x^2 + \\Delta x^3)O(\\Delta x^6) + (1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!})O(\\Delta x^4) + O(\\Delta x^4)O(\\Delta x^6) $$\n",
    "\n",
    "$$ = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + \\dots + O(\\Delta x^4) + O(\\Delta x^6) + O(\\Delta x^4)O(\\Delta x^6) $$\n",
    "\n",
    "$$ \\therefore O(\\Delta x^4)O(\\Delta x^6) = O(\\Delta x^10) $$\n",
    "\n",
    "    and \n",
    "\n",
    "$$ O(\\Delta x^4) + O(\\Delta x^6) + O(\\Delta x^10) = O(\\Delta x^4)$$\n",
    "\n",
    "$$ \\therefore (\\frac{1}{1-\\Delta x})(\\cosh \\Delta x) = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^4) $$\n",
    "\n",
    "    Order of Approximation: \n",
    "\n",
    "$$ O(\\Delta x^4) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "237fcd7151c710b1c2fe86744794671b",
     "grade": false,
     "grade_id": "cell-5632471080286207",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 3:  The great Exp challenge...\n",
    "\n",
    "Here you will attempt to write a function to calculate $e^x$ using its Taylor polynomial approximation expanded around $x_0=0$\n",
    "\n",
    "$$e^x \\approx T_n(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots + \\frac{x^n}{n!}$$\n",
    "\n",
    "such that the relative error of $f=e^x$ and $F=T_n(x)$ is of order Machine epsilon ($\\epsilon_{machine}$) for  $x\\in[-50,50]$.  This problem is actually a bit of a stinker and takes a bit of thought (particularly for $x<0$).  But I'll work you through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d16eac32cec2913a95095d153a7994b7",
     "grade": false,
     "grade_id": "cell-8186992197557199",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** [4 pts] Assume $x> 0$ and show that the upper bound on the *relative error*  at term $n$ \n",
    "\n",
    "$$r_n = \\frac{|e^x - T_n(x)|}{|e^x|}$$\n",
    "\n",
    "is given by\n",
    "\n",
    "$$r_n \\leq \\left | \\frac{x^{n+1}}{(n + 1)!} \\right |$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c066945aa96e6e08fcb676cf3b3e08f3",
     "grade": true,
     "grade_id": "cell-2747685663052674",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$$ |e^{x} - T_n(x) |= \\frac{x^{n+1}}{(n+1)!} + \\frac{x^{n+2}}{(n+2)!} + \\dots $$\n",
    "\n",
    "$$ |e^{x} - T_n(x)| = | \\frac{x^{n+1}}{(n+1)!} | | 1+ \\frac{x}{(n+2)!} + \\dots | $$\n",
    "\n",
    "$$ |e^{x} - T_n(x)| ≤ | \\frac{x^{n+1}}{(n+1)!} | |1 + x + \\frac{x^{2}}{2} + \\dots|$$ \n",
    "\n",
    "    Note that the latter part of equation is equal to \n",
    "\n",
    "$$ e^x $$\n",
    "\n",
    "$$ \\therefore |e^{x} - T_n(x) |≤ | \\frac{x^{n+1}}{(n+1)!} | | e^{x} |$$ \n",
    "\n",
    "$$ \\therefore r_n = |\\frac{|e^x - T_n(x)|}{|e^x|}| ≤ | \\frac{x^{n+1}}{(n+1)!} |$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d99909b59608e280edc2f24b68c644e",
     "grade": false,
     "grade_id": "cell-4678254376542691",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** [4 pts] Analytically show that for large $x$ and $n$, $r_n \\leq \\epsilon_{\\text{machine}}$ implies that we need at least $n > e \\cdot x$ terms in the series (where $e = \\text{exp}(1)$).\n",
    "\n",
    "*Hint* Use Stirling's approximation $log (n!) \\approx n~log~n - n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8152aede9f1e1f429a231ee2b82df69c",
     "grade": true,
     "grade_id": "cell-4305745011657702",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$$ r_n ≤ | \\frac{x^{n+1}}{(n + 1)!} | ≤ e_{machine} $$\n",
    "\n",
    "    Take log of both sides \n",
    "\n",
    "$$ log | \\frac{x^{n+1}}{(n + 1)!} | ≤ log(e_{machine}) $$\n",
    "\n",
    "$$ (n + 1)log|x| - log((n+1)!) ≤ log(e_{machine}) $$\n",
    "\n",
    "$$ (n + 1)log|x| - nlogn - n ≤ log(e_{machine}) $$\n",
    "\n",
    "$$ n(log|x| - logn - 1) + log|x| ≤ log(e_{machine})$$\n",
    "\n",
    "$$ log(\\frac{x}{n+1}^{n+1}) - n - 1 ≤ log(e_{machine}) $$\n",
    "\n",
    "$$ e^{log(\\frac{x}{n+1})^{n+1}} ≤ e_{machine} $$\n",
    "\n",
    "$$ \\frac{\\frac{x}{n+1}^{n+1}}{e^{n+1}} ≤ e_{machine} $$\n",
    "\n",
    "$$ (\\frac{\\frac{x}{n+1}}{e})^{n+1} ≤ e_{machine} $$\n",
    "\n",
    "$$ \\frac{xe}{n+1} \\geq (e_{machine})^{\\frac{1}{n+1}} $$\n",
    "\n",
    "$$ xe \\geq (e_{machine})^{\\frac{1}{n+1}} (n+1) $$\n",
    "\n",
    "    We know: \n",
    "    \n",
    "$$ (e_{machine})^{\\frac{1}{n+1}} < 1 $$\n",
    "\n",
    "$$ \\therefore xe > n $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1f116abbde0e2ff962c5fcb4ab286ae",
     "grade": false,
     "grade_id": "cell-8048500717179941",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** [6 pts] Use this result to write a Python function that accurately approximates $e^x$ using $T_n(x)$ for scalar $x$ and returns both the estimate and the number of terms in the series.  Note that the testing tolerance will be $8 \\cdot \\epsilon_{\\text{machine}}$ over the range $x\\in[-50,50]$\n",
    "\n",
    "Make sure to document your code including expected inputs, outputs, and assumptions being made.\n",
    "\n",
    "Some Hints:\n",
    "* To make your life easier,  we will assume $x$ and $Tn(x)$ are just of type float (not arrays)\n",
    "* Think about how we evaluated polynomials efficiently in class\n",
    "* $T_N(x)$ for $x<0$ is a highly unstable alternating series with severe cancellation issues. However, there is a simple fix that will return accurate solutions independent of the sign of $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80286c759520479af4ce906ac70f62e5",
     "grade": false,
     "grade_id": "cell-5914967225034965",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def Tn_exp(x):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "\n",
    "    assert(isinstance(x,float))\n",
    "    # rough estimate of maximum number of steps for large x\n",
    "    # MAX_N = ??\n",
    "    \n",
    "    # This will help make the caclulations simple, I will add the negative sign again at the end if necessary \n",
    "    if x >= 0:\n",
    "        is_negative = False\n",
    "    elif x < 0:\n",
    "        is_negative = True  \n",
    "        x = -x\n",
    "        \n",
    "    MAX_N = numpy.intc(3 * x) * 10 \n",
    "    \n",
    "    n = numpy.arange(MAX_N, -1, -1)\n",
    "    p = 1. / factorial(n)\n",
    "    \n",
    "    Tn = p[0]\n",
    "    \n",
    "    for i in  p[1:]:\n",
    "        Tn = Tn * x + i \n",
    "    \n",
    "    # make Tn the inverse of Tn to accomodate a negative x float \n",
    "    if is_negative: \n",
    "        Tn = 1. / Tn\n",
    "        \n",
    "    \n",
    "    return Tn, MAX_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4462a62a8a268cb02646317c28222126",
     "grade": true,
     "grade_id": "cell-9688375319882602",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 4.252190255480811 eps_machine\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "x = numpy.linspace(-50, 50, 101)\n",
    "eps = numpy.finfo(float).eps\n",
    "tolerance = 8 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b1d4a353e51fbba1658f5a6968d1b42",
     "grade": false,
     "grade_id": "cell-c154452f653c5adc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(d)** [4 pts] In ieee double precision,  the largest value of $x$ that has $e^x<$ `numpy.finfo(float).max` is about 709 (i.e. `numpy.log(numpy.finfo(float).max))`. \n",
    "\n",
    "* What is the relative error in units of machine epsilon for your routine and `f=numpy.exp(709)`\n",
    "* What is the relative error in units of machine epsilon for `F=numpy.exp(1)**709` and `f=numpy.exp(709)`\n",
    "\n",
    "Explain your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f: 8.218407461554972e+307\n",
      "Value of F: 7.37704835207159e+177\n",
      "maxmimum relative error = 4503599627370496.0 eps_machine\n",
      "Value of f: 8.218407461554972e+307\n",
      "Value of F: 8.218407461554662e+307\n",
      "maxmimum relative error = 170.0702257577037 eps_machine\n"
     ]
    }
   ],
   "source": [
    "# relative error for f = numpy.exp(709) and F = Tn_exp(709)\n",
    "\n",
    "f = numpy.exp(709)\n",
    "F, n = Tn_exp(709.)\n",
    "\n",
    "print('Value of f:', f)\n",
    "print('Value of F:', F) \n",
    "\n",
    "e = numpy.abs(F - f) / numpy.abs(numpy.exp(709))\n",
    "print('maxmimum relative error = {} eps_machine'.format(e.max()/eps))\n",
    "\n",
    "# relative error for f = numpy.exp(709) and F = Tn_exp(709)\n",
    "\n",
    "f = numpy.exp(709)\n",
    "F = numpy.exp(1) ** 709\n",
    "\n",
    "print('Value of f:', f)\n",
    "print('Value of F:', F) \n",
    "\n",
    "e = numpy.abs(F - f) / numpy.abs(numpy.exp(709))\n",
    "print('maxmimum relative error = {} eps_machine'.format(e.max()/eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5a47ab9f08e7fe4764609703387ef9d",
     "grade": true,
     "grade_id": "cell-26e754d164cf2a3a",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The better approximation for exp(709) seems to be numpy.exp(1) ** 709. Since 709 is the upper bound for double precision, it makes sense that the precision at n = 709 would deviate by a significant amount when we call our approximation Tn_exp(709). Furthermore, while our calculation is an approximation, numpy.exp(1) ** 709 essentially is the mathematical definition of exp(709), therefore it is very very close and any difference can be attributed to rounding precision.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7acaa725abfd22229bddd35f652e4b57",
     "grade": false,
     "grade_id": "cell-aaa3ac7c64bd5868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(e)** **Extra Credit**\n",
    "\n",
    "[4 pts] Can you modify your routine for `Tn_exp(x)`) to approximate $e^x$ on the range $x\\in[-709, 709]$ to within 16 $\\epsilon_{machine}$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c184e65af5b8e5f46c673245638f9ef",
     "grade": false,
     "grade_id": "cell-28a21d2a7d0bda99",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-15b94d1fa268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47c964bd17be30e90d2a8b03d580466c",
     "grade": true,
     "grade_id": "cell-96883753198883843",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tn_exp() got an unexpected keyword argument 'tolerance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2e6c1c622a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTn_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maxmimum relative error = {} eps_machine'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tn_exp() got an unexpected keyword argument 'tolerance'"
     ]
    }
   ],
   "source": [
    "x = numpy.linspace(-709, 709, 101)\n",
    "tolerance = 16 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi, tolerance=tolerance)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cf2d7b203d87a2041de63aebcfb15c9",
     "grade": false,
     "grade_id": "cell-6605000347660435",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "Consider a computing system that uses deoxyribonucleic acid (DNA) to store information.  Given that DNA is formed from the 4 nucleobases adenine, cytosine, guanine, and thymine (uracil is only found in RNA) let us assume that our storage of numbers will be base 4.  Answer the following questions based on this assuming that we have $p=3$ for the mantissa and the exponent $E \\in [-2, 2]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47f4d67565808d7f75e55f0689f21dd6",
     "grade": false,
     "grade_id": "cell-9339658002746268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** [4 pts] Calculate how many numbers can we represent with this system?  What are the underflow and overflow limits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0255974fb370e1c331638d41f074ddf",
     "grade": true,
     "grade_id": "cell-623b625975f5da41",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$$ f = \\pm d_1 . d_2d_3 \\times 4^E, \\quad E \\in [-2, 2] $$\n",
    "$$ 2 \\times 3 \\times 4 \\times 4 \\times 5 + 1 = 481 $$\n",
    "\n",
    "    Total Numbers: 385 \n",
    "\n",
    "    Smallest number that can be represented is the underflow:  \n",
    "\n",
    "$$1.00 \\times 4^{-2} = 0.0625$$\n",
    "\n",
    "    Largest number that can be represented is the overflow:  \n",
    "    \n",
    "$$3.33 \\times 4^2 = 53.28 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29c7fc5ca0808f62a6b35897f3fbbe87",
     "grade": false,
     "grade_id": "cell-9339658dsfsdf46268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** [4pts] Graphically show how the numbers on the decimal real line are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b95cccb5e3723bc4ebd7a1a10500f39a",
     "grade": true,
     "grade_id": "cell-4c6d3ae47566d1f1",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_1_values = [1, 2, 3]\n",
    "d_2_values = [0, 1, 2, 3]\n",
    "d_3_values = [0, 1, 2, 3]\n",
    "E_values = [-2, -1, 0, 1, 2]\n",
    "\n",
    "fig = plt.figure(figsize=(10.0, 1.0))\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for E in E_values:\n",
    "    for d1 in d_1_values:\n",
    "        for d2 in d_2_values:\n",
    "            for d3 in d_3_values:\n",
    "                axes.plot( (d1 + (d2 * 0.25) + (d3 * 0.25 * 0.25)) * 4**E, 0.0, 'r+', markersize=20)\n",
    "                axes.plot(-(d1 + (d2 * 0.25) + (d3 * 0.25 * 0.25)) * 4**E, 0.0, 'r+', markersize=20)\n",
    "            \n",
    "axes.plot(0.0, 0.0, '+', markersize=20)\n",
    "axes.plot([-10.0, 10.0], [0.0, 0.0], 'k')\n",
    "\n",
    "axes.set_title(\"Distribution of Values\")\n",
    "axes.set_yticks([])\n",
    "axes.set_xlabel(\"x\")\n",
    "axes.set_ylabel(\"\")\n",
    "axes.set_xlim([-1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bf4d21af32acd12ada842602e2343ad",
     "grade": false,
     "grade_id": "cell-93396552502746268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** [4 pts] How many more numbers can we store in $N$ base-pairs (base 4) versus $N$ bits (base 2) where the mantissa and exponent are the same relative length (e.g.  p=3, and $E\\in[-2,2]$ for both problems)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16825fa4b75b7fc34d854b1653fe64b8",
     "grade": true,
     "grade_id": "cell-6de5d8dbf91c5ff7",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$$f=\\pm d_1 . d_2d_3 \\times 2^E ~~~~ \\text{with} ~~~~ E \\in [-2, 2]$$\n",
    "$$ 2 \\times 1 \\times 2 \\times 5 + 1 = 21 $$\n",
    "\n",
    "    Total Numbers: 41\n",
    "    \n",
    "$$ 481 - 21 = 460 $$\n",
    "\n",
    "    There are 460 more numbers that we can store in base 4 within -2 < E < 2 and a mantissa of 3 than we can with the same characteristics in base 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
